import{_ as n,c as e,f as t,o as a}from"./app-C2DDjOfb.js";const s={};function o(r,i){return a(),e("div",null,i[0]||(i[0]=[t('<h1 id="_01basics" tabindex="-1"><a class="header-anchor" href="#_01basics"><span>01Basics</span></a></h1><h2 id="_1-tokenization" tabindex="-1"><a class="header-anchor" href="#_1-tokenization"><span>1. Tokenization</span></a></h2><div class="custom-container definition"><p class="custom-container-title">Definition (Tokenization)</p><div class="custom-container-content"><h1 id="" tabindex="-1"><a class="header-anchor" href="#"><span></span></a></h1><p>A Tokenizer is a class that encodes strings into tokens ( <code>string -&gt; int[]</code> ) and decodes tokens back into strings ( <code>int[] -&gt; string</code> ).</p></div></div><div class="custom-container definition"><p class="custom-container-title">Definition (Compression Ratio)</p><div class="custom-container-content"><h1 id="" tabindex="-1"><a class="header-anchor" href="#"><span></span></a></h1><p>Compression Raion = <code>len(bytes(string)) / len(indices)</code></p></div></div><ul><li><strong>Charater-based Tokenization</strong>: Each character can be converted into a interger.</li><li><strong>Byte-based Tokenization</strong>: Unicode strings can be represented as a sequence of bytes, which compression ratio is 1.</li><li><strong>Word-based Tokenization</strong>: Split strings into words and map each word into an integer.</li></ul><h3 id="_1-1-byte-pair-encoding" tabindex="-1"><a class="header-anchor" href="#_1-1-byte-pair-encoding"><span>1.1 Byte Pair Encoding</span></a></h3><div class="custom-container definition"><p class="custom-container-title">Definition (BPE)</p><div class="custom-container-content"><h1 id="" tabindex="-1"><a class="header-anchor" href="#"><span></span></a></h1><p>Based on byte-level, merge frequent pairs of bytes into new tokens.</p></div></div><h2 id="_2-primitives-in-training" tabindex="-1"><a class="header-anchor" href="#_2-primitives-in-training"><span>2. Primitives in training</span></a></h2>',8)]))}const d=n(s,[["render",o],["__file","01Basics.html.vue"]]),l=JSON.parse('{"path":"/series/stanford/cs336/01Basics.html","title":"01Basics","lang":"zh-CN","frontmatter":{"date":"2025-09-23T00:00:00.000Z"},"headers":[{"level":2,"title":"1. Tokenization","slug":"_1-tokenization","link":"#_1-tokenization","children":[{"level":3,"title":"1.1 Byte Pair Encoding","slug":"_1-1-byte-pair-encoding","link":"#_1-1-byte-pair-encoding","children":[]}]},{"level":2,"title":"2. Primitives in training","slug":"_2-primitives-in-training","link":"#_2-primitives-in-training","children":[]}],"git":{"createdTime":1760432072000,"updatedTime":1760432072000,"contributors":[{"name":"Dawnfz-Lenfeng","email":"2912706234@qq.com","commits":1}]},"filePathRelative":"series/stanford/cs336/01Basics.md"}');export{d as comp,l as data};
