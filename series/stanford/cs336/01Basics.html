<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="generator" content="VuePress 2.0.0-rc.19">
    <script>
      (function() {
        const userMode = localStorage.getItem('vuepress-reco-color-scheme') || 'auto';
        const systemDarkMode = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;

        if (userMode === 'dark' || (userMode === 'auto' && systemDarkMode)) {
          document.documentElement.classList.toggle('dark', true);
        }
      })();
    </script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"><title>01Basics | Lingfeng's Starry Night</title><meta name="description" content="A blog of Lingfeng">
    <link rel="preload" href="/assets/style-Bxs6G3Ej.css" as="style"><link rel="stylesheet" href="/assets/style-Bxs6G3Ej.css">
    <link rel="modulepreload" href="/assets/app-aIn2dQ2S.js"><link rel="modulepreload" href="/assets/01Basics.html-BmR2a6Bz.js">
    <link rel="prefetch" href="/assets/timeline.html-CKJe9Dy0.js" as="script"><link rel="prefetch" href="/assets/posts.html-Dyglqu4n.js" as="script"><link rel="prefetch" href="/assets/friendship-link.html-Bn7MoI3o.js" as="script"><link rel="prefetch" href="/assets/1.html-DAyfPNMY.js" as="script"><link rel="prefetch" href="/assets/1.html-CSluKHJd.js" as="script"><link rel="prefetch" href="/assets/1.html-C5I4cCCl.js" as="script"><link rel="prefetch" href="/assets/1.html-DdRN9a2d.js" as="script"><link rel="prefetch" href="/assets/index.html-CTfX63sJ.js" as="script"><link rel="prefetch" href="/assets/index.html-B5pGCGK5.js" as="script"><link rel="prefetch" href="/assets/HelloWorld.html-B_11hw3L.js" as="script"><link rel="prefetch" href="/assets/KLsanduyuVAE.html-yU9iKXPt.js" as="script"><link rel="prefetch" href="/assets/index.html-DWTTH3Me.js" as="script"><link rel="prefetch" href="/assets/shanggujuanzhou5——cishengbuwangaiyouxijiangshiyihan.html-IxeZnPf3.js" as="script"><link rel="prefetch" href="/assets/liyongHexoyuGithubPagedajiangerenboke.html-C8pVfjvK.js" as="script"><link rel="prefetch" href="/assets/xiaoji.html-D23_G0Vi.js" as="script"><link rel="prefetch" href="/assets/xingkongdeqinxian.html-DwagFZHc.js" as="script"><link rel="prefetch" href="/assets/index.html-DlnT-MNM.js" as="script"><link rel="prefetch" href="/assets/01yiyuanxianxinghuigui.html-EbabXNAL.js" as="script"><link rel="prefetch" href="/assets/02-1duoyuanxianxinghuigui.html-bWeltphQ.js" as="script"><link rel="prefetch" href="/assets/02-2duoyuanxianxinghuigui-moxingtuiduan.html-CohfpxtX.js" as="script"><link rel="prefetch" href="/assets/02-3duoyuanxianxinghuigui-zhongxinhuahebiaozhunhua.html-DQmJ7umK.js" as="script"><link rel="prefetch" href="/assets/03weibeijibenjiashedeqingkuang.html-RG_E3Ax_.js" as="script"><link rel="prefetch" href="/assets/04duozhonggongxianxing.html-D3fmk_Mq.js" as="script"><link rel="prefetch" href="/assets/05moxingxuanze.html-HeGROE_p.js" as="script"><link rel="prefetch" href="/assets/06guangyixianxinghuiguimoxing.html-B8apQePh.js" as="script"><link rel="prefetch" href="/assets/shiyongjuzhentuidaoyiyuanxianxinghuiguixiangguangongshi.html--3VmPj0I.js" as="script"><link rel="prefetch" href="/assets/guangyipianFjianyan.html-b8S4y8A4.js" as="script"><link rel="prefetch" href="/assets/01yubeizhishi.html-DEf-4rx-.js" as="script"><link rel="prefetch" href="/assets/02wuyueshuzuiyouhuafangfadejibenjiegou.html-C-jTOKta.js" as="script"><link rel="prefetch" href="/assets/03wuyueshuyouhua-yijiefangfa.html-CTbga0dE.js" as="script"><link rel="prefetch" href="/assets/04wuyueshuyouhua-erjiefangfa.html-LceQt0ho.js" as="script"><link rel="prefetch" href="/assets/05wuyueshuyouhua-zuixiaoerchengfa.html-i8F-FqBT.js" as="script"><link rel="prefetch" href="/assets/06yueshuzuiyouhuawenti.html-tos7ZluY.js" as="script"><link rel="prefetch" href="/assets/07fahanshufa.html-CsEeuRGo.js" as="script"><link rel="prefetch" href="/assets/01yiweifeijunyunsuijishudechansheng.html-D3-UDTg9.js" as="script"><link rel="prefetch" href="/assets/02suijixiangliangsuijishuchouyang.html-BOocu4Ml.js" as="script"><link rel="prefetch" href="/assets/03canshuguji.html-DcorUEOY.js" as="script"><link rel="prefetch" href="/assets/04jiashejianyan.html-BPRH0ZqO.js" as="script"><link rel="prefetch" href="/assets/05jianshaofangchadetongjifangfa.html-DAfcM7UJ.js" as="script"><link rel="prefetch" href="/assets/06zhongchouyangsuanfa.html-D6wH11gH.js" as="script"><link rel="prefetch" href="/assets/07EMsuanfa.html-BGAKU19P.js" as="script"><link rel="prefetch" href="/assets/01yinyan.html-CzHRTh8p.js" as="script"><link rel="prefetch" href="/assets/02wuliceng.html-B6Z86mTy.js" as="script"><link rel="prefetch" href="/assets/03shujulianluceng.html-vqQRxQ7w.js" as="script"><link rel="prefetch" href="/assets/04MACziceng.html-DevZFYw6.js" as="script"><link rel="prefetch" href="/assets/05wangluoceng.html-CGT3iSEH.js" as="script"><link rel="prefetch" href="/assets/06chuanshuceng.html-AT6-QAyd.js" as="script"><link rel="prefetch" href="/assets/07yingyongceng.html-DQvBi5tW.js" as="script"><link rel="prefetch" href="/assets/01xianxingguihuayudanchunxingfa.html-DsKpTTkH.js" as="script"><link rel="prefetch" href="/assets/02duiouwentiyulingmindufenxi.html-B60itfIF.js" as="script"><link rel="prefetch" href="/assets/03yunshuwenti.html-D_FqQEbM.js" as="script"><link rel="prefetch" href="/assets/04zhengshuguihua.html-C-aVMsKg.js" as="script"><link rel="prefetch" href="/assets/01yubeizhishi.html-DN0OuB67.js" as="script"><link rel="prefetch" href="/assets/02-1bosongguocheng.html-pZvaueaS.js" as="script"><link rel="prefetch" href="/assets/02-2bosongguocheng-bosongguochengdetuiguang.html-DEk5n9Mc.js" as="script"><link rel="prefetch" href="/assets/03-1gengxinguocheng.html-vhhJ7f6i.js" as="script"><link rel="prefetch" href="/assets/03-2gengxinguocheng-gengxinguochengdetuiguang.html-BogFkQXW.js" as="script"><link rel="prefetch" href="/assets/04-1Markovlian.html-DSwt75Ea.js" as="script"><link rel="prefetch" href="/assets/04-2Markovlian-lianxushijian.html-CjSbetcl.js" as="script"><link rel="prefetch" href="/assets/05yang.html-Cgxvq6cA.js" as="script"><link rel="prefetch" href="/assets/06bulangyundong.html-B2lpCOMN.js" as="script"><link rel="prefetch" href="/assets/01zhanyuduilie.html-BNwJSdqY.js" as="script"><link rel="prefetch" href="/assets/02KMPsuanfa.html-J7G3SzB4.js" as="script"><link rel="prefetch" href="/assets/03paixu.html-CldjlXE-.js" as="script"><link rel="prefetch" href="/assets/04sousuo.html-Bj8b_46Z.js" as="script"><link rel="prefetch" href="/assets/05shu.html-DUMZQ2a_.js" as="script"><link rel="prefetch" href="/assets/06tu.html-VKIQvh0-.js" as="script"><link rel="prefetch" href="/assets/01shijianyugailv.html-D6ikYfja.js" as="script"><link rel="prefetch" href="/assets/02suijibianliangyufenbu.html-C-4QCwEM.js" as="script"><link rel="prefetch" href="/assets/03shuzitezhengyutezhenghanshu.html-8AfSDsV2.js" as="script"><link rel="prefetch" href="/assets/04changjianfenbu.html-DtqwfE7y.js" as="script"><link rel="prefetch" href="/assets/05jixiandingli.html-gaXeCgkn.js" as="script"><link rel="prefetch" href="/assets/01-1xinglieshi.html-DCeBnopW.js" as="script"><link rel="prefetch" href="/assets/01-2xinglieshixiti.html-B2ocDIBe.js" as="script"><link rel="prefetch" href="/assets/02xianxingfangchengzu.html-w0haFiOg.js" as="script"><link rel="prefetch" href="/assets/03-1juzhen.html-fqHtvEnp.js" as="script"><link rel="prefetch" href="/assets/03-2juzhendezhizhuanti.html-Bitq9IaA.js" as="script"><link rel="prefetch" href="/assets/04ercixing.html-Dzx-nqhC.js" as="script"><link rel="prefetch" href="/assets/05tezhengzhiyutezhengxiangliang.html-CQPgSqqq.js" as="script"><link rel="prefetch" href="/assets/404.html-DzEDXD2C.js" as="script"><link rel="prefetch" href="/assets/Valine.min-CdX76AvO.js" as="script"><link rel="prefetch" href="/assets/giscus-aTimukGI-2nVLKbCi.js" as="script"><link rel="prefetch" href="/assets/AboutContent-b6BFZOlJ.js" as="script"><link rel="prefetch" href="/assets/AboutSection-0ipYQK26.js" as="script"><link rel="prefetch" href="/assets/IconBook-DyRn-ugV.js" as="script"><link rel="prefetch" href="/assets/IconEdit-DOPeVXgf.js" as="script"><link rel="prefetch" href="/assets/IconGithub-B9SU2FRu.js" as="script"><link rel="prefetch" href="/assets/IconHome-BCV6teUH.js" as="script"><link rel="prefetch" href="/assets/IconMessage-Gi8ZSBCL.js" as="script"><link rel="prefetch" href="/assets/IconUser-BWm0jQ03.js" as="script"><link rel="prefetch" href="/assets/IntroCard-CTKgSoqc.js" as="script"><link rel="prefetch" href="/assets/StarrySky-CdYRTM_r.js" as="script"><link rel="prefetch" href="/assets/setupDevtools-7MC2TMWH-DhNhPgLZ.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><div class="theme-container show-series show-catalog"><header class="navbar-container not-open"><div class="navbar-inner"><div class="site-brand nav-item"><img class="logo" src="/favicon.ico" alt="Lingfeng&#39;s Starry Night"><a href="/" class="site-name can-hide">Lingfeng&#39;s Starry Night</a></div><div class="nav-item navbar-links-wrapper" style=""><div><form class="search-box" role="search"><input type="search" autocomplete="off" spellcheck="false" value><!----></form></div><nav class="navbar-links"><!--[--><div class="navbar-links__item"><a href="/" class="link" aria-label="首页"><!--[--><!--]--><span class="xicon-container left"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 24 24" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;"><path d="M10 20v-6h4v6h5v-8h3L12 3 2 12h3v8z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->首页<!--]--></span></span><!--[--><!--]--></a></div><div class="navbar-links__item"><a href="/blogs/" class="link" aria-label="博客"><!--[--><!--]--><span class="xicon-container left"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 24 24" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;"><path d="M3 17.25V21h3.75L17.81 9.94l-3.75-3.75L3 17.25zM20.71 7.04c.39-.39.39-1.02 0-1.41l-2.34-2.34c-.39-.39-1.02-.39-1.41 0l-1.83 1.83 3.75 3.75 1.83-1.83z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->博客<!--]--></span></span><!--[--><!--]--></a></div><div class="navbar-links__item"><div class="dropdown-link"><button class="dropdown-link__title" type="button" aria-label="课程笔记"><span class="xicon-container left title"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 24 24" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;"><path d="M18 2H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h12c1.1 0 2-.9 2-2V4c0-1.1-.9-2-2-2zM6 4h5v8l-2.5-1.5L6 12V4z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->课程笔记<!--]--></span></span><span class="arrow down"></span></button><button class="dropdown-link--mobile__title" type="button" aria-label="课程笔记"><span class="title"><span class="xicon-container left"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 24 24" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;"><path d="M18 2H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h12c1.1 0 2-.9 2-2V4c0-1.1-.9-2-2-2zM6 4h5v8l-2.5-1.5L6 12V4z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->课程笔记<!--]--></span></span></span><span class="right arrow"></span></button><ul style="display:none;" class="dropdown-link__container"><!--[--><li class="dropdown-link__item"><a href="/series/courses/huiguifenxi/01yiyuanxianxinghuigui" class="link" aria-label="回归分析"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->回归分析<!--]--></span></span><!--[--><!--]--></a></li><li class="dropdown-link__item"><a href="/series/courses/zuiyouhuafangfa/01yubeizhishi" class="link" aria-label="最优化方法"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->最优化方法<!--]--></span></span><!--[--><!--]--></a></li><li class="dropdown-link__item"><a href="/series/courses/tongjijisuan/01yiweifeijunyunsuijishudechansheng" class="link" aria-label="统计计算"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->统计计算<!--]--></span></span><!--[--><!--]--></a></li><li class="dropdown-link__item"><a href="/series/courses/jisuanjiwangluo/01yinyan" class="link" aria-label="计算机网络"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->计算机网络<!--]--></span></span><!--[--><!--]--></a></li><li class="dropdown-link__item"><a href="/series/courses/yunchouxue/01xianxingguihuayudanchunxingfa" class="link" aria-label="运筹学"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->运筹学<!--]--></span></span><!--[--><!--]--></a></li><li class="dropdown-link__item"><a href="/series/courses/suijiguocheng/01yubeizhishi" class="link" aria-label="随机过程"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->随机过程<!--]--></span></span><!--[--><!--]--></a></li><!--]--></ul></div></div><div class="navbar-links__item"><div class="dropdown-link"><button class="dropdown-link__title" type="button" aria-label="夏令营复习"><span class="xicon-container left title"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 24 24" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;"><path d="M18 2H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h12c1.1 0 2-.9 2-2V4c0-1.1-.9-2-2-2zM6 4h5v8l-2.5-1.5L6 12V4z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->夏令营复习<!--]--></span></span><span class="arrow down"></span></button><button class="dropdown-link--mobile__title" type="button" aria-label="夏令营复习"><span class="title"><span class="xicon-container left"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 24 24" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;"><path d="M18 2H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h12c1.1 0 2-.9 2-2V4c0-1.1-.9-2-2-2zM6 4h5v8l-2.5-1.5L6 12V4z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->夏令营复习<!--]--></span></span></span><span class="right arrow"></span></button><ul style="display:none;" class="dropdown-link__container"><!--[--><li class="dropdown-link__item"><a href="/series/fuxi/shujujiegou/01zhanyuduilie" class="link" aria-label="数据结构"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->数据结构<!--]--></span></span><!--[--><!--]--></a></li><li class="dropdown-link__item"><a href="/series/fuxi/gailvlun/01shijianyugailv" class="link" aria-label="概率论"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->概率论<!--]--></span></span><!--[--><!--]--></a></li><li class="dropdown-link__item"><a href="/series/fuxi/xianxingdaishu/01-1xinglieshi" class="link" aria-label="线性代数"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->线性代数<!--]--></span></span><!--[--><!--]--></a></li><!--]--></ul></div></div><div class="navbar-links__item"><div class="dropdown-link"><button class="dropdown-link__title--active dropdown-link__title" type="button" aria-label="Stanford"><span class="xicon-container left title"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 24 24" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;"><path d="M18 2H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h12c1.1 0 2-.9 2-2V4c0-1.1-.9-2-2-2zM6 4h5v8l-2.5-1.5L6 12V4z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->Stanford<!--]--></span></span><span class="arrow down"></span></button><button class="dropdown-link--mobile__title" type="button" aria-label="Stanford"><span class="title"><span class="xicon-container left"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 24 24" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;"><path d="M18 2H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h12c1.1 0 2-.9 2-2V4c0-1.1-.9-2-2-2zM6 4h5v8l-2.5-1.5L6 12V4z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->Stanford<!--]--></span></span></span><span class="right arrow"></span></button><ul style="display:none;" class="dropdown-link__container"><!--[--><li class="dropdown-link__item"><a href="/series/stanford/cs336/01Basics" class="link router-link-active" aria-label="cs336"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->cs336<!--]--></span></span><!--[--><!--]--></a></li><!--]--></ul></div></div><div class="navbar-links__item"><a href="/about/" class="link" aria-label="关于我"><!--[--><!--]--><span class="xicon-container left"><!--[--><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;"><path d="M20 21v-2a4 4 0 0 0-4-4H8a4 4 0 0 0-4 4v2"></path><circle cx="12" cy="7" r="4"></circle></svg><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->关于我<!--]--></span></span><!--[--><!--]--></a></div><div class="navbar-links__item"><a href="/message-board/" class="link" aria-label="留言板"><!--[--><!--]--><span class="xicon-container left"><!--[--><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;"><path d="M21 15a2 2 0 0 1-2 2H7l-4 4V5a2 2 0 0 1 2-2h14a2 2 0 0 1 2 2z"></path><line x1="9" y1="10" x2="15" y2="10"></line></svg><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->留言板<!--]--></span></span><!--[--><!--]--></a></div><!--]--><!----><span class="xicon-container btn-toggle-dark-mode btn--dark-mode navbar-links__item"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 32 32" style="width:20px;height:20px;font-size:20px;color:;"><path d="M15 2h2v3h-2z" fill="currentColor"></path><path d="M27 15h3v2h-3z" fill="currentColor"></path><path d="M15 27h2v3h-2z" fill="currentColor"></path><path d="M2 15h3v2H2z" fill="currentColor"></path><path d="M5.45 6.884l1.414-1.415l2.121 2.122l-1.414 1.414z" fill="currentColor"></path><path d="M23 7.58l2.121-2.12l1.414 1.414l-2.121 2.121z" fill="currentColor"></path><path d="M23.002 24.416l1.415-1.414l2.12 2.122l-1.413 1.414z" fill="currentColor"></path><path d="M5.47 25.13L7.59 23L9 24.42l-2.12 2.12l-1.41-1.41z" fill="currentColor"></path><path d="M16 8a8 8 0 1 0 8 8a8 8 0 0 0-8-8zm0 14a6 6 0 0 1 0-12z" fill="currentColor"></path></svg></span><ul class="social-links navbar-links__item"><!--[--><li class="social-item"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 32 32" style="width:25px;height:25px;"><path d="M16 2a14 14 0 0 0-4.43 27.28c.7.13 1-.3 1-.67v-2.38c-3.89.84-4.71-1.88-4.71-1.88a3.71 3.71 0 0 0-1.62-2.05c-1.27-.86.1-.85.1-.85a2.94 2.94 0 0 1 2.14 1.45a3 3 0 0 0 4.08 1.16a2.93 2.93 0 0 1 .88-1.87c-3.1-.36-6.37-1.56-6.37-6.92a5.4 5.4 0 0 1 1.44-3.76a5 5 0 0 1 .14-3.7s1.17-.38 3.85 1.43a13.3 13.3 0 0 1 7 0c2.67-1.81 3.84-1.43 3.84-1.43a5 5 0 0 1 .14 3.7a5.4 5.4 0 0 1 1.44 3.76c0 5.38-3.27 6.56-6.39 6.91a3.33 3.33 0 0 1 .95 2.59v3.84c0 .46.25.81 1 .67A14 14 0 0 0 16 2z" fill-rule="evenodd" fill="currentColor"></path></svg></li><!--]--></ul></nav><span class="xicon-container btn-toggle-menus"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 32 32" style="width:20px;height:20px;font-size:20px;color:;"><circle cx="16" cy="8" r="2" fill="currentColor"></circle><circle cx="16" cy="16" r="2" fill="currentColor"></circle><circle cx="16" cy="24" r="2" fill="currentColor"></circle></svg></span></div></div></header><header class="sub-navbar-container not-open"><span class="nav-item"><div class="toggle-series-button" aria-expanded="false" role="button" tabindex="0"><span></span><span></span><span></span></div> Series </span></header><!----><!----><div class="theme-main" style=""><aside class="series-container"><!--[--><!--[--><section class="series-group series-item"><h5 class="series-heading series-level-1 active"><span class="xicon-container left"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 32 32" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;"><path d="M11.17 6l3.42 3.41l.58.59H28v16H4V6h7.17m0-2H4a2 2 0 0 0-2 2v20a2 2 0 0 0 2 2h24a2 2 0 0 0 2-2V10a2 2 0 0 0-2-2H16l-3.41-3.41A2 2 0 0 0 11.17 4z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:;font-size:16px;"><!--[-->cs336<!--]--></span></span><span class="arrow down"></span></h5><ul style="display:block;"><li><!--[--><a aria-current="page" href="/series/stanford/cs336/01Basics.html" class="router-link-active router-link-exact-active link router-link-active series-item series-item" aria-label="01Basics"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->01Basics<!--]--></span></span><!--[--><!--]--></a><!--]--></li></ul></section><!--]--><!--]--></aside><!--[--><main class="page-container"><div class="page-content"><h1 class="page-title">01Basics</h1><div class="page-info"><span class="xicon-container left"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 32 32" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;"><path d="M16 4a5 5 0 1 1-5 5a5 5 0 0 1 5-5m0-2a7 7 0 1 0 7 7a7 7 0 0 0-7-7z" fill="currentColor"></path><path d="M26 30h-2v-5a5 5 0 0 0-5-5h-6a5 5 0 0 0-5 5v5H6v-5a7 7 0 0 1 7-7h6a7 7 0 0 1 7 7z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->Lingfeng<!--]--></span></span><span class="xicon-container left"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 32 32" class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;"><path d="M26 4h-4V2h-2v2h-8V2h-2v2H6c-1.1 0-2 .9-2 2v20c0 1.1.9 2 2 2h20c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zm0 22H6V12h20v14zm0-16H6V6h4v2h2V6h8v2h2V6h4v4z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->2025-09-23<!--]--></span></span><!----><!----><span class="xicon-container left"><!--[--><svg class="xicon-icon" style="width:18px;height:18px;font-size:18px;color:;font-size:18px;" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 12 12"><g fill="none"><path d="M1.974 6.659a.5.5 0 0 1-.948-.317c-.01.03 0-.001 0-.001a1.633 1.633 0 0 1 .062-.162c.04-.095.099-.226.18-.381c.165-.31.422-.723.801-1.136C2.834 3.827 4.087 3 6 3c1.913 0 3.166.827 3.931 1.662a5.479 5.479 0 0 1 .98 1.517l.046.113c.003.008.013.06.023.11L11 6.5s.084.333-.342.474a.5.5 0 0 1-.632-.314v-.003l-.006-.016a3.678 3.678 0 0 0-.172-.376a4.477 4.477 0 0 0-.654-.927C8.584 4.673 7.587 4 6 4s-2.584.673-3.194 1.338a4.477 4.477 0 0 0-.795 1.225a2.209 2.209 0 0 0-.03.078l-.007.018zM6 5a2 2 0 1 0 0 4a2 2 0 0 0 0-4zM5 7a1 1 0 1 1 2 0a1 1 0 0 1-2 0z" fill="currentColor"></path></g></svg><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[--><span id="/series/stanford/cs336/01Basics.html" class="leancloud-visitors" data-flag-title="Your Article Title"><a class="leancloud-visitors-count" style=""></a></span><!----><!--]--></span></span></div><div class="theme-reco-md-content"><div><h1 id="_01basics" tabindex="-1"><a class="header-anchor" href="#_01basics"><span>01Basics</span></a></h1><p>完整代码实现见 <a href="https://github.com/Dawnfz-Lenfeng/cs336-basic" target="_blank" rel="noopener noreferrer">Dawnfz-Lenfeng/cs336-basic<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>。</p><h2 id="_1-bpe-tokenization" tabindex="-1"><a class="header-anchor" href="#_1-bpe-tokenization"><span>1. BPE Tokenization</span></a></h2><h3 id="_1-1-bpe-tokenizer-training" tabindex="-1"><a class="header-anchor" href="#_1-1-bpe-tokenizer-training"><span>1.1 BPE Tokenizer Training</span></a></h3><p>BPE 训练部分主要包括训练流程如下：</p><ul><li><strong>Vocabulary initialzation</strong>：用 <code>bytes</code> 初始化 <code>vocab</code></li><li><strong>Pre-tokenization</strong>：对文本分词成 <code>pretoken</code>，计数 <code>pretoken</code> 以计数 <code>token</code></li><li><strong>Pop most frequent pair</strong>：pop 出最频繁的 <code>token_pair</code> 作为 <code>new_token</code></li><li><strong>Merge</strong>：把 <code>token</code> 中的 <code>token_pair</code> 合并为 <code>new_token</code>，进入循环</li></ul><p>完整实现如下：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">def</span> <span class="token function">train_bpe</span><span class="token punctuation">(</span></span>
<span class="line">    input_path<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">|</span> os<span class="token punctuation">.</span>PathLike<span class="token punctuation">,</span></span>
<span class="line">    vocab_size<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span></span>
<span class="line">    special_tokens<span class="token punctuation">:</span> <span class="token builtin">list</span><span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line"><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">tuple</span><span class="token punctuation">[</span><span class="token builtin">dict</span><span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">bytes</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token builtin">list</span><span class="token punctuation">[</span><span class="token builtin">tuple</span><span class="token punctuation">[</span><span class="token builtin">bytes</span><span class="token punctuation">,</span> <span class="token builtin">bytes</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">:</span></span>
<span class="line">    vocab <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token builtin">bytes</span><span class="token punctuation">(</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">]</span></span>
<span class="line">    merges <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></span>
<span class="line"></span>
<span class="line">    pretoken_counts <span class="token operator">=</span> pretokenize<span class="token punctuation">(</span>input_path<span class="token punctuation">,</span> special_tokens<span class="token punctuation">)</span></span>
<span class="line">    pair_counts<span class="token punctuation">,</span> pair2pretoken <span class="token operator">=</span> pretoken2pair<span class="token punctuation">(</span>pretoken_counts<span class="token punctuation">)</span></span>
<span class="line">    pair_heap <span class="token operator">=</span> LazyHeap<span class="token punctuation">(</span><span class="token builtin">dict</span><span class="token punctuation">(</span>pair_counts<span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">    num_merges <span class="token operator">=</span> vocab_size <span class="token operator">-</span> <span class="token builtin">len</span><span class="token punctuation">(</span>vocab<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token builtin">len</span><span class="token punctuation">(</span>special_tokens<span class="token punctuation">)</span></span>
<span class="line">    <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_merges<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">        pair <span class="token operator">=</span> pop_most_frequent_pair<span class="token punctuation">(</span>pair_heap<span class="token punctuation">,</span> vocab<span class="token punctuation">)</span></span>
<span class="line">        byte1<span class="token punctuation">,</span> byte2 <span class="token operator">=</span> <span class="token builtin">map</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> vocab<span class="token punctuation">[</span>x<span class="token punctuation">]</span><span class="token punctuation">,</span> pair<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        merges<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>byte1<span class="token punctuation">,</span> byte2<span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line">        vocab<span class="token punctuation">.</span>append<span class="token punctuation">(</span>byte1 <span class="token operator">+</span> byte2<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        merge_pair<span class="token punctuation">(</span>pretoken_counts<span class="token punctuation">,</span> pair_heap<span class="token punctuation">,</span> pair2pretoken<span class="token punctuation">,</span> pair<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>vocab<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">    vocab<span class="token punctuation">.</span>extend<span class="token punctuation">(</span>token<span class="token punctuation">.</span>encode<span class="token punctuation">(</span><span class="token string">&quot;utf-8&quot;</span><span class="token punctuation">)</span> <span class="token keyword">for</span> token <span class="token keyword">in</span> special_tokens<span class="token punctuation">)</span></span>
<span class="line">    <span class="token keyword">return</span> <span class="token punctuation">{</span>i<span class="token punctuation">:</span> token <span class="token keyword">for</span> i<span class="token punctuation">,</span> token <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>vocab<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span> merges</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>优化思路</strong></p><p><strong>Pre-tokenization</strong>：主要针对大文件优化，大文件 <code>pretokenize</code> 是瓶颈。在 <code>tinystories</code> 数据集上 load memory 会比较有压力，因此把文件切分成 <code>chunk</code> 多进程 <code>pretokenize</code>。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">def</span> <span class="token function">find_chunk_bounds</span><span class="token punctuation">(</span></span>
<span class="line">    <span class="token builtin">file</span><span class="token punctuation">:</span> BinaryIO<span class="token punctuation">,</span></span>
<span class="line">    split_special_token<span class="token punctuation">:</span> <span class="token builtin">bytes</span><span class="token punctuation">,</span></span>
<span class="line">    chunk_size<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">5</span> <span class="token operator">*</span> <span class="token number">1024</span> <span class="token operator">*</span> <span class="token number">1024</span><span class="token punctuation">,</span></span>
<span class="line"><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">list</span><span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token triple-quoted-string string">&quot;&quot;&quot;Chunk the file into parts that can be counted independently&quot;&quot;&quot;</span></span>
<span class="line">    <span class="token builtin">file</span><span class="token punctuation">.</span>seek<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> os<span class="token punctuation">.</span>SEEK_END<span class="token punctuation">)</span></span>
<span class="line">    file_size <span class="token operator">=</span> <span class="token builtin">file</span><span class="token punctuation">.</span>tell<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">    <span class="token builtin">file</span><span class="token punctuation">.</span>seek<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">    bounds <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span></span>
<span class="line"></span>
<span class="line">    <span class="token keyword">for</span> pos <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> file_size<span class="token punctuation">,</span> chunk_size<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">        chunk <span class="token operator">=</span> <span class="token builtin">file</span><span class="token punctuation">.</span>read<span class="token punctuation">(</span>chunk_size<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        <span class="token keyword">if</span> <span class="token punctuation">(</span>found_at <span class="token operator">:=</span> chunk<span class="token punctuation">.</span>rfind<span class="token punctuation">(</span>split_special_token<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span></span>
<span class="line">            bounds<span class="token punctuation">.</span>append<span class="token punctuation">(</span>pos <span class="token operator">+</span> found_at <span class="token operator">+</span> <span class="token builtin">len</span><span class="token punctuation">(</span>split_special_token<span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">    bounds<span class="token punctuation">.</span>append<span class="token punctuation">(</span>file_size<span class="token punctuation">)</span></span>
<span class="line">    <span class="token keyword">return</span> bounds</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>Pop most frequent pair</strong>：考虑用 <code>LazyHeap</code> 优化 <code>find_max</code> 操作，需要 <code>dict</code> + <code>heap</code> 以实现 O(1) 的查找、更改、删除、<code>max</code> 操作。由于 <code>count</code> 相同时需要比较最大字典序，而 Python 仅支持最小堆，如果仅通过堆操作则需要构造 <code>ReversedPair</code> 对象。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">class</span> <span class="token class-name">ReversedPair</span><span class="token punctuation">:</span></span>
<span class="line">    vocab<span class="token punctuation">:</span> <span class="token builtin">list</span><span class="token punctuation">[</span><span class="token builtin">bytes</span><span class="token punctuation">]</span></span>
<span class="line"></span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> pair<span class="token punctuation">:</span> <span class="token builtin">tuple</span><span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">        self<span class="token punctuation">.</span>pair <span class="token operator">=</span> pair</span>
<span class="line"></span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">__lt__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> other<span class="token punctuation">:</span> <span class="token string">&quot;ReversedPair&quot;</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">bool</span><span class="token punctuation">:</span></span>
<span class="line">        self_pair <span class="token operator">=</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>vocab<span class="token punctuation">[</span>self<span class="token punctuation">.</span>pair<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>vocab<span class="token punctuation">[</span>self<span class="token punctuation">.</span>pair<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line">        other_pair <span class="token operator">=</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>vocab<span class="token punctuation">[</span>other<span class="token punctuation">.</span>pair<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>vocab<span class="token punctuation">[</span>other<span class="token punctuation">.</span>pair<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line">        <span class="token keyword">return</span> self_pair <span class="token operator">&gt;</span> other_pair</span>
<span class="line"></span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">__eq__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> other<span class="token punctuation">:</span> <span class="token string">&quot;ReversedPair&quot;</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">bool</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token keyword">return</span> self<span class="token punctuation">.</span>pair <span class="token operator">==</span> other<span class="token punctuation">.</span>pair</span>
<span class="line"></span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">__hash__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">int</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token keyword">return</span> <span class="token builtin">hash</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>pair<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">    <span class="token decorator annotation punctuation">@classmethod</span></span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">set_vocab</span><span class="token punctuation">(</span>cls<span class="token punctuation">,</span> vocab<span class="token punctuation">:</span> <span class="token builtin">list</span><span class="token punctuation">[</span><span class="token builtin">bytes</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">        cls<span class="token punctuation">.</span>vocab <span class="token operator">=</span> vocab</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>但实际上创建对象开销会比较高，在频繁的 Pop 中真正需要字典序排序的场景并不多，因此不如 Pop 出所有频率相同的 <code>pair</code>，手动比较字典序性能更好。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">def</span> <span class="token function">pop_most_frequent_pair</span><span class="token punctuation">(</span></span>
<span class="line">    pair_heap<span class="token punctuation">:</span> LazyHeap<span class="token punctuation">,</span></span>
<span class="line">    vocab<span class="token punctuation">:</span> <span class="token builtin">list</span><span class="token punctuation">[</span><span class="token builtin">bytes</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line"><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">tuple</span><span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token triple-quoted-string string">&quot;&quot;&quot;Pop the most frequent pair in the vocabulary&quot;&quot;&quot;</span></span>
<span class="line">    max_pair<span class="token punctuation">,</span> max_count <span class="token operator">=</span> pair_heap<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">    vocab_order <span class="token operator">=</span> <span class="token punctuation">(</span>vocab<span class="token punctuation">[</span>max_pair<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> vocab<span class="token punctuation">[</span>max_pair<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">    pairs_to_restore<span class="token punctuation">:</span> <span class="token builtin">list</span><span class="token punctuation">[</span><span class="token builtin">tuple</span><span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></span>
<span class="line">    <span class="token keyword">while</span> pair_heap<span class="token punctuation">:</span></span>
<span class="line">        top<span class="token punctuation">,</span> top_count <span class="token operator">=</span> pair_heap<span class="token punctuation">.</span>top<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">        <span class="token keyword">if</span> top_count <span class="token operator">&lt;</span> max_count<span class="token punctuation">:</span></span>
<span class="line">            <span class="token keyword">break</span></span>
<span class="line">        <span class="token comment"># if count is the same, compare their lex order</span></span>
<span class="line">        <span class="token keyword">if</span> <span class="token punctuation">(</span>new_order <span class="token operator">:=</span> <span class="token punctuation">(</span>vocab<span class="token punctuation">[</span>top<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> vocab<span class="token punctuation">[</span>top<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&gt;</span> vocab_order<span class="token punctuation">:</span></span>
<span class="line">            pairs_to_restore<span class="token punctuation">.</span>append<span class="token punctuation">(</span>max_pair<span class="token punctuation">)</span></span>
<span class="line">            max_pair<span class="token punctuation">,</span> vocab_order <span class="token operator">=</span> top<span class="token punctuation">,</span> new_order</span>
<span class="line">        <span class="token keyword">else</span><span class="token punctuation">:</span></span>
<span class="line">            pairs_to_restore<span class="token punctuation">.</span>append<span class="token punctuation">(</span>top<span class="token punctuation">)</span></span>
<span class="line">        pair_heap<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">    <span class="token keyword">for</span> pair <span class="token keyword">in</span> pairs_to_restore<span class="token punctuation">:</span></span>
<span class="line">        pair_heap<span class="token punctuation">[</span>pair<span class="token punctuation">]</span> <span class="token operator">=</span> max_count</span>
<span class="line"></span>
<span class="line">    <span class="token keyword">return</span> max_pair</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>Merge</strong>：得到 <code>new_token</code> 后，需要找到对应的 <code>pretoken</code> 从而更新 <code>pair_count</code>。一方面可以缓存 <code>pair2pretoken</code> ，O(1) 进行查找；另一方面只记录需要更新的 <code>pretoken</code>，增量更新 <code>pair_count</code>。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">def</span> <span class="token function">merge_pair</span><span class="token punctuation">(</span></span>
<span class="line">    pretoken_counts<span class="token punctuation">:</span> Counter<span class="token punctuation">[</span><span class="token builtin">tuple</span><span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">    pair_heap<span class="token punctuation">:</span> LazyHeap<span class="token punctuation">,</span></span>
<span class="line">    pair2pretoken<span class="token punctuation">:</span> <span class="token builtin">dict</span><span class="token punctuation">[</span><span class="token builtin">tuple</span><span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token builtin">set</span><span class="token punctuation">[</span><span class="token builtin">tuple</span><span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">    pair_to_merge<span class="token punctuation">:</span> <span class="token builtin">tuple</span><span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">    new_token<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span></span>
<span class="line"><span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token triple-quoted-string string">&quot;&quot;&quot;Merge a pair of tokens in the pretoken counts, updating the counts of the new and adjacent pairs&quot;&quot;&quot;</span></span>
<span class="line">    items_to_merge <span class="token operator">=</span> <span class="token punctuation">[</span></span>
<span class="line">        <span class="token punctuation">(</span>pretoken<span class="token punctuation">,</span> pretoken_counts<span class="token punctuation">[</span>pretoken<span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line">        <span class="token keyword">for</span> pretoken <span class="token keyword">in</span> pair2pretoken<span class="token punctuation">[</span>pair_to_merge<span class="token punctuation">]</span></span>
<span class="line">    <span class="token punctuation">]</span></span>
<span class="line"></span>
<span class="line">    <span class="token keyword">for</span> pretoken<span class="token punctuation">,</span> count <span class="token keyword">in</span> items_to_merge<span class="token punctuation">:</span></span>
<span class="line">        new_pretoken<span class="token punctuation">,</span> pair_delta <span class="token operator">=</span> _merge_pretoken<span class="token punctuation">(</span></span>
<span class="line">            pretoken<span class="token punctuation">,</span> count<span class="token punctuation">,</span> pair_to_merge<span class="token punctuation">,</span> new_token</span>
<span class="line">        <span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        <span class="token keyword">del</span> pretoken_counts<span class="token punctuation">[</span>pretoken<span class="token punctuation">]</span></span>
<span class="line">        _remove_pretoken_from_pairs<span class="token punctuation">(</span>pretoken<span class="token punctuation">,</span> pair2pretoken<span class="token punctuation">)</span></span>
<span class="line">        <span class="token comment"># filter len(pretoken) &lt; 2</span></span>
<span class="line">        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>new_pretoken<span class="token punctuation">)</span> <span class="token operator">&gt;=</span> <span class="token number">2</span><span class="token punctuation">:</span></span>
<span class="line">            pretoken_counts<span class="token punctuation">[</span>new_pretoken<span class="token punctuation">]</span> <span class="token operator">+=</span> count</span>
<span class="line">            _add_pretoken_to_pairs<span class="token punctuation">(</span>new_pretoken<span class="token punctuation">,</span> pair2pretoken<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        <span class="token keyword">for</span> pair<span class="token punctuation">,</span> delta_count <span class="token keyword">in</span> pair_delta<span class="token punctuation">:</span></span>
<span class="line">            pair_heap<span class="token punctuation">[</span>pair<span class="token punctuation">]</span> <span class="token operator">+=</span> delta_count</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>其中 <code>_merge_pretoken</code> 需要处理比较复杂的边界情况：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">def</span> <span class="token function">_merge_pretoken</span><span class="token punctuation">(</span></span>
<span class="line">    pretoken<span class="token punctuation">:</span> <span class="token builtin">tuple</span><span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">    count<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span></span>
<span class="line">    pair_to_merge<span class="token punctuation">:</span> <span class="token builtin">tuple</span><span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">    new_token<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span></span>
<span class="line"><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">tuple</span><span class="token punctuation">[</span><span class="token builtin">tuple</span><span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token builtin">list</span><span class="token punctuation">[</span><span class="token builtin">tuple</span><span class="token punctuation">[</span><span class="token builtin">tuple</span><span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">:</span></span>
<span class="line">    new_pretoken <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></span>
<span class="line">    pair_delta <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></span>
<span class="line"></span>
<span class="line">    i <span class="token operator">=</span> <span class="token number">0</span></span>
<span class="line">    <span class="token keyword">while</span> i <span class="token operator">&lt;</span> <span class="token builtin">len</span><span class="token punctuation">(</span>pretoken<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token keyword">if</span> i <span class="token operator">+</span> <span class="token number">1</span> <span class="token operator">==</span> <span class="token builtin">len</span><span class="token punctuation">(</span>pretoken<span class="token punctuation">)</span> <span class="token keyword">or</span> <span class="token punctuation">(</span>pretoken<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> pretoken<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">!=</span> pair_to_merge<span class="token punctuation">:</span></span>
<span class="line">	        new_pretoken<span class="token punctuation">.</span>append<span class="token punctuation">(</span>pretoken<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line">            i <span class="token operator">+=</span> <span class="token number">1</span></span>
<span class="line">            <span class="token keyword">continue</span></span>
<span class="line"></span>
<span class="line">		<span class="token comment"># left adjacent pair</span></span>
<span class="line">		<span class="token keyword">if</span> i <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">:</span></span>
<span class="line">			<span class="token keyword">if</span> new_pretoken<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">==</span> new_token<span class="token punctuation">:</span></span>
<span class="line">				pair_delta<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token punctuation">(</span>new_token<span class="token punctuation">,</span> new_token<span class="token punctuation">)</span><span class="token punctuation">,</span> count<span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line">				<span class="token comment"># if adjacent pairs have been merged,</span></span>
<span class="line">				<span class="token comment"># left&#39;s (new_token, pretoken[i + 2]) pair has been +count wrongly</span></span>
<span class="line">				pair_delta<span class="token punctuation">.</span>remove<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token punctuation">(</span>new_token<span class="token punctuation">,</span> pretoken<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> count<span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line">			<span class="token keyword">else</span><span class="token punctuation">:</span></span>
<span class="line">				pair_delta<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token punctuation">(</span>pretoken<span class="token punctuation">[</span>i <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> pretoken<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span>count<span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line">				pair_delta<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token punctuation">(</span>pretoken<span class="token punctuation">[</span>i <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> new_token<span class="token punctuation">)</span><span class="token punctuation">,</span> count<span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">		<span class="token comment"># right adjacent pair</span></span>
<span class="line">		<span class="token keyword">if</span> i <span class="token operator">+</span> <span class="token number">2</span> <span class="token operator">&lt;</span> <span class="token builtin">len</span><span class="token punctuation">(</span>pretoken<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">			pair_delta<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token punctuation">(</span>pretoken<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> pretoken<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span>count<span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line">			pair_delta<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token punctuation">(</span>new_token<span class="token punctuation">,</span> pretoken<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> count<span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">		new_pretoken<span class="token punctuation">.</span>append<span class="token punctuation">(</span>new_token<span class="token punctuation">)</span></span>
<span class="line">		i <span class="token operator">+=</span> <span class="token number">2</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line">    <span class="token keyword">return</span> <span class="token builtin">tuple</span><span class="token punctuation">(</span>new_pretoken<span class="token punctuation">)</span><span class="token punctuation">,</span> pair_delta</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_1-2-bpe-tokenizer" tabindex="-1"><a class="header-anchor" href="#_1-2-bpe-tokenizer"><span>1.2 BPE Tokenizer</span></a></h3><p><code>Tokenizer</code> 实现相对 <code>train_bpe</code> 简单不少，主要接口为 <code>encode: str -&gt; list[int]</code> 和 <code>decode: list[int] -&gt; str</code>。</p><p><strong>Encode</strong>：encode 过程与 <code>merge</code> 类似，先把文本拆分成 <code>pretoken</code>，<strong>按照 <code>merges</code> 列表中的合并顺序迭代合并</strong>，最终通过 <code>vocab</code> 转换为 <code>token_ids</code>。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">def</span> <span class="token function">encode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> text<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">list</span><span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token keyword">if</span> <span class="token keyword">not</span> text<span class="token punctuation">:</span></span>
<span class="line">        <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></span>
<span class="line"></span>
<span class="line">    <span class="token keyword">if</span> self<span class="token punctuation">.</span>special_pattern<span class="token punctuation">:</span></span>
<span class="line">	    parts <span class="token operator">=</span> self<span class="token punctuation">.</span>special_pattern<span class="token punctuation">.</span>split<span class="token punctuation">(</span>text<span class="token punctuation">)</span></span>
<span class="line">	<span class="token keyword">else</span><span class="token punctuation">:</span></span>
<span class="line">	    parts <span class="token operator">=</span> <span class="token punctuation">[</span>text<span class="token punctuation">]</span></span>
<span class="line"></span>
<span class="line">	ids <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></span>
<span class="line">	<span class="token keyword">for</span> part <span class="token keyword">in</span> parts<span class="token punctuation">:</span></span>
<span class="line">	    <span class="token keyword">if</span> <span class="token keyword">not</span> part<span class="token punctuation">:</span></span>
<span class="line">	        <span class="token keyword">continue</span></span>
<span class="line"></span>
<span class="line">	    <span class="token keyword">if</span> part <span class="token keyword">in</span> self<span class="token punctuation">.</span>special_tokens<span class="token punctuation">:</span></span>
<span class="line">	        ids<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>encoder<span class="token punctuation">[</span>part<span class="token punctuation">.</span>encode<span class="token punctuation">(</span><span class="token string">&#39;utf-8&#39;</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line">	        <span class="token keyword">continue</span></span>
<span class="line"></span>
<span class="line">        pretokens <span class="token operator">=</span> <span class="token punctuation">[</span></span>
<span class="line">            <span class="token punctuation">[</span>self<span class="token punctuation">.</span>encoder<span class="token punctuation">[</span>b<span class="token punctuation">]</span> <span class="token keyword">for</span> b <span class="token keyword">in</span> <span class="token keyword">match</span><span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>encode<span class="token punctuation">(</span><span class="token string">&#39;utf-8&#39;</span><span class="token punctuation">)</span><span class="token punctuation">]</span></span>
<span class="line">            <span class="token keyword">for</span> <span class="token keyword">match</span> <span class="token keyword">in</span> PAT<span class="token punctuation">.</span>finditer<span class="token punctuation">(</span>part<span class="token punctuation">)</span>  <span class="token comment"># pretokenize</span></span>
<span class="line">        <span class="token punctuation">]</span></span>
<span class="line">        ids<span class="token punctuation">.</span>extend<span class="token punctuation">(</span></span>
<span class="line">            self<span class="token punctuation">.</span>encoder<span class="token punctuation">[</span>token<span class="token punctuation">]</span></span>
<span class="line">            <span class="token keyword">for</span> pretoken <span class="token keyword">in</span> pretokens</span>
<span class="line">            <span class="token keyword">for</span> token <span class="token keyword">in</span> self<span class="token punctuation">.</span>_merge_pretoken<span class="token punctuation">(</span>pretoken<span class="token punctuation">)</span></span>
<span class="line">        <span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><code>_merge_pretoken</code> 需要找到合并顺序，因此需要在初始化时额外构造 <code>self.ranks = {pair: i for i, pair in enumarate(merges)}</code>。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">def</span> <span class="token function">_merge_pretoken</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> pretoken<span class="token punctuation">:</span> <span class="token builtin">list</span><span class="token punctuation">[</span><span class="token builtin">bytes</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">list</span><span class="token punctuation">[</span><span class="token builtin">bytes</span><span class="token punctuation">]</span><span class="token punctuation">:</span></span>
<span class="line">	<span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>pretoken<span class="token punctuation">)</span> <span class="token operator">&lt;</span> <span class="token number">2</span><span class="token punctuation">:</span></span>
<span class="line">		<span class="token keyword">return</span> pretoken</span>
<span class="line"></span>
<span class="line">	<span class="token keyword">while</span> <span class="token builtin">len</span><span class="token punctuation">(</span>pretoken<span class="token punctuation">)</span> <span class="token operator">&gt;=</span> <span class="token number">2</span><span class="token punctuation">:</span></span>
<span class="line">		pair_to_merge <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span></span>
<span class="line">			<span class="token builtin">zip</span><span class="token punctuation">(</span>pretoken<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> pretoken<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">			key<span class="token operator">=</span><span class="token keyword">lambda</span> pair<span class="token punctuation">:</span> self<span class="token punctuation">.</span>ranks<span class="token punctuation">.</span>get<span class="token punctuation">(</span>pair<span class="token punctuation">,</span> <span class="token builtin">float</span><span class="token punctuation">(</span><span class="token string">&quot;inf&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">		<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">		<span class="token keyword">if</span> pair_to_merge <span class="token keyword">not</span> <span class="token keyword">in</span> self<span class="token punctuation">.</span>ranks<span class="token punctuation">:</span></span>
<span class="line">			<span class="token keyword">break</span></span>
<span class="line"></span>
<span class="line">		new_pretoken <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span></span>
<span class="line">		i <span class="token operator">=</span> <span class="token number">0</span></span>
<span class="line">		<span class="token keyword">while</span> i <span class="token operator">&lt;</span> <span class="token builtin">len</span><span class="token punctuation">(</span>pretoken<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">			<span class="token keyword">if</span> <span class="token punctuation">(</span></span>
<span class="line">				i <span class="token operator">+</span> <span class="token number">1</span> <span class="token operator">&lt;</span> <span class="token builtin">len</span><span class="token punctuation">(</span>pretoken<span class="token punctuation">)</span></span>
<span class="line">				<span class="token keyword">and</span> <span class="token punctuation">(</span>pretoken<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> pretoken<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">==</span> pair_to_merge</span>
<span class="line">			<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">				new_pretoken<span class="token punctuation">.</span>append<span class="token punctuation">(</span>pretoken<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+</span> pretoken<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line">				i <span class="token operator">+=</span> <span class="token number">2</span></span>
<span class="line">			<span class="token keyword">else</span><span class="token punctuation">:</span></span>
<span class="line">				new_pretoken<span class="token punctuation">.</span>append<span class="token punctuation">(</span>pretoken<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line">				i <span class="token operator">+=</span> <span class="token number">1</span></span>
<span class="line"></span>
<span class="line">		pretoken <span class="token operator">=</span> new_pretoken</span>
<span class="line"></span>
<span class="line">	<span class="token keyword">return</span> pretoken</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>Decode</strong>：decode 非常简单，使用 <code>vocab</code> 查询即可：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">def</span> <span class="token function">decode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> ids<span class="token punctuation">:</span> <span class="token builtin">list</span><span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">str</span><span class="token punctuation">:</span></span>
<span class="line">	<span class="token keyword">if</span> <span class="token keyword">not</span> ids<span class="token punctuation">:</span></span>
<span class="line">		<span class="token keyword">return</span> <span class="token string">&quot;&quot;</span></span>
<span class="line"></span>
<span class="line">	<span class="token keyword">return</span> <span class="token string">b&quot;&quot;</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>self<span class="token punctuation">.</span>vocab<span class="token punctuation">[</span><span class="token builtin">id</span><span class="token punctuation">]</span> <span class="token keyword">for</span> <span class="token builtin">id</span> <span class="token keyword">in</span> ids<span class="token punctuation">)</span><span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token string">&quot;utf-8&quot;</span><span class="token punctuation">,</span> errors<span class="token operator">=</span><span class="token string">&quot;replace&quot;</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_2-transformer-language-model-architecture" tabindex="-1"><a class="header-anchor" href="#_2-transformer-language-model-architecture"><span>2. Transformer Language Model Architecture</span></a></h2><p>原文档采用自下而上的方式，这里我们采用自上而下的方式。总架构图如下所示：</p><p><img src="https://raw.githubusercontent.com/Dawnfz-Lenfeng/imgs/master/20251015214054158.png" alt="image.png"></p><p>实际只会输出 logits，即到 Linear 层，代码架构如下：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">class</span> <span class="token class-name">TransformerLM</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span></span>
<span class="line">        self<span class="token punctuation">,</span></span>
<span class="line">        vocab_size<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span></span>
<span class="line">        context_length<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span></span>
<span class="line">        d_model<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span></span>
<span class="line">        num_layers<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span></span>
<span class="line">        num_heads<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span></span>
<span class="line">        d_ff<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span></span>
<span class="line">        rope_theta<span class="token punctuation">:</span> <span class="token builtin">float</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        self<span class="token punctuation">.</span>token_embeddings <span class="token operator">=</span> Embedding<span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span> d_model<span class="token punctuation">)</span></span>
<span class="line">        self<span class="token punctuation">.</span>layers <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span></span>
<span class="line">            TransformerBlock<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> d_ff<span class="token punctuation">,</span> context_length<span class="token punctuation">,</span> rope_theta<span class="token punctuation">)</span></span>
<span class="line">            <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_layers<span class="token punctuation">)</span></span>
<span class="line">        <span class="token punctuation">)</span></span>
<span class="line">        self<span class="token punctuation">.</span>ln_final <span class="token operator">=</span> RMSNorm<span class="token punctuation">(</span>d_model<span class="token punctuation">)</span></span>
<span class="line">        self<span class="token punctuation">.</span>lm_head <span class="token operator">=</span> Linear<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> vocab_size<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span></span>
<span class="line">        self<span class="token punctuation">,</span></span>
<span class="line">        x<span class="token punctuation">:</span> Int<span class="token punctuation">[</span>Tensor<span class="token punctuation">,</span> <span class="token string">&quot; ... seq_len&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Float<span class="token punctuation">[</span>Tensor<span class="token punctuation">,</span> <span class="token string">&quot; ... seq_len vocab&quot;</span><span class="token punctuation">]</span><span class="token punctuation">:</span></span>
<span class="line">        x <span class="token operator">=</span> self<span class="token punctuation">.</span>token_embeddings<span class="token punctuation">(</span>x<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        <span class="token keyword">for</span> block <span class="token keyword">in</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">:</span></span>
<span class="line">            x <span class="token operator">=</span> block<span class="token punctuation">(</span>x<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        x <span class="token operator">=</span> self<span class="token punctuation">.</span>ln_final<span class="token punctuation">(</span>x<span class="token punctuation">)</span></span>
<span class="line">        logits <span class="token operator">=</span> self<span class="token punctuation">.</span>lm_head<span class="token punctuation">(</span>x<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        <span class="token keyword">return</span> logits</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_2-1-linear-module" tabindex="-1"><a class="header-anchor" href="#_2-1-linear-module"><span>2.1 Linear Module</span></a></h3><p>Linear 是最基础的模块，功能为对空间维度进行变换 <code>(..., in_features) -&gt; (..., out_features)</code>，在 LM 最后将 <code>d_model -&gt; vocab_size</code>。参数尺寸为 <code>(d_out, d_in)</code>。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">class</span> <span class="token class-name">Linear</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span></span>
<span class="line">        self<span class="token punctuation">,</span></span>
<span class="line">        in_features<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span></span>
<span class="line">        out_features<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span></span>
<span class="line">        device<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>device <span class="token operator">|</span> <span class="token boolean">None</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span></span>
<span class="line">        dtype<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>dtype <span class="token operator">|</span> <span class="token boolean">None</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        std <span class="token operator">=</span> math<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span><span class="token number">2.0</span> <span class="token operator">/</span> <span class="token punctuation">(</span>in_features <span class="token operator">+</span> out_features<span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line">        self<span class="token punctuation">.</span>weight <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span></span>
<span class="line">            nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>trunc_normal_<span class="token punctuation">(</span></span>
<span class="line">                torch<span class="token punctuation">.</span>empty<span class="token punctuation">(</span></span>
<span class="line">                    <span class="token punctuation">(</span>out_features<span class="token punctuation">,</span> in_features<span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">                    device<span class="token operator">=</span>device<span class="token punctuation">,</span></span>
<span class="line">                    dtype<span class="token operator">=</span>dtype<span class="token punctuation">,</span></span>
<span class="line">                <span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">                std<span class="token operator">=</span>std<span class="token punctuation">,</span></span>
<span class="line">                a<span class="token operator">=</span><span class="token operator">-</span><span class="token number">3</span> <span class="token operator">*</span> std<span class="token punctuation">,</span></span>
<span class="line">                b<span class="token operator">=</span><span class="token number">3</span> <span class="token operator">*</span> std<span class="token punctuation">,</span></span>
<span class="line">            <span class="token punctuation">)</span></span>
<span class="line">        <span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> Float<span class="token punctuation">[</span>Tensor<span class="token punctuation">,</span> <span class="token string">&quot; ... d_in&quot;</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Float<span class="token punctuation">[</span>Tensor<span class="token punctuation">,</span> <span class="token string">&quot; ... d_out&quot;</span><span class="token punctuation">]</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token keyword">return</span> x @ self<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>T</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_2-2-embedding-module" tabindex="-1"><a class="header-anchor" href="#_2-2-embedding-module"><span>2.2 Embedding Module</span></a></h3><p>Embedding 主要做映射操作，即 <code>vocab_size -&gt; d_model</code>，关联到 torch 的张量操作就是索引操作，参数尺寸为 <code>(vocab_size, d_model)</code>：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">class</span> <span class="token class-name">Embedding</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span></span>
<span class="line">        self<span class="token punctuation">,</span></span>
<span class="line">        vocab_size<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span></span>
<span class="line">        d_model<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span></span>
<span class="line">        device<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>device <span class="token operator">|</span> <span class="token boolean">None</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span></span>
<span class="line">        dtype<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>dtype <span class="token operator">|</span> <span class="token boolean">None</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        std <span class="token operator">=</span> <span class="token number">1.0</span></span>
<span class="line">        self<span class="token punctuation">.</span>weight <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span></span>
<span class="line">            nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>trunc_normal_<span class="token punctuation">(</span></span>
<span class="line">                torch<span class="token punctuation">.</span>empty<span class="token punctuation">(</span><span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span> d_model<span class="token punctuation">)</span><span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">,</span> dtype<span class="token operator">=</span>dtype<span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">                std<span class="token operator">=</span>std<span class="token punctuation">,</span></span>
<span class="line">                a<span class="token operator">=</span><span class="token operator">-</span><span class="token number">3</span> <span class="token operator">*</span> std<span class="token punctuation">,</span></span>
<span class="line">                b<span class="token operator">=</span><span class="token number">3</span> <span class="token operator">*</span> std<span class="token punctuation">,</span></span>
<span class="line">            <span class="token punctuation">)</span></span>
<span class="line">        <span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> token_ids<span class="token punctuation">:</span> Int<span class="token punctuation">[</span>Tensor<span class="token punctuation">,</span> <span class="token string">&quot; ...&quot;</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Float<span class="token punctuation">[</span>Tensor<span class="token punctuation">,</span> <span class="token string">&quot; ... d_model&quot;</span><span class="token punctuation">]</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token keyword">return</span> self<span class="token punctuation">.</span>weight<span class="token punctuation">[</span>token_ids<span class="token punctuation">]</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_2-3-transformer-block" tabindex="-1"><a class="header-anchor" href="#_2-3-transformer-block"><span>2.3 Transformer Block</span></a></h3><p>Transformer Block 架构如下，先经过 Self-Attention 层，再经过一个 FFN：</p><p><img src="https://raw.githubusercontent.com/Dawnfz-Lenfeng/imgs/master/20251015215406393.png" alt="image.png"></p><p>代码如下：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">class</span> <span class="token class-name">TransformerBlock</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span></span>
<span class="line">        self<span class="token punctuation">,</span></span>
<span class="line">        d_model<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span></span>
<span class="line">        num_heads<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span></span>
<span class="line">        d_ff<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span></span>
<span class="line">        max_seq_len<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span></span>
<span class="line">        theta<span class="token punctuation">:</span> <span class="token builtin">float</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        self<span class="token punctuation">.</span>ln1 <span class="token operator">=</span> RMSNorm<span class="token punctuation">(</span>d_model<span class="token punctuation">)</span></span>
<span class="line">        self<span class="token punctuation">.</span>attn <span class="token operator">=</span> MultiheadSelfAttention<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> theta<span class="token punctuation">,</span> max_seq_len<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        self<span class="token punctuation">.</span>ln2 <span class="token operator">=</span> RMSNorm<span class="token punctuation">(</span>d_model<span class="token punctuation">)</span></span>
<span class="line">        self<span class="token punctuation">.</span>ffn <span class="token operator">=</span> SwiGlu<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> d_ff<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span></span>
<span class="line">        self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> Float<span class="token punctuation">[</span>Tensor<span class="token punctuation">,</span> <span class="token string">&quot; ... seq_len d_model&quot;</span><span class="token punctuation">]</span></span>
<span class="line">    <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Float<span class="token punctuation">[</span>Tensor<span class="token punctuation">,</span> <span class="token string">&quot; ... seq_len d_model&quot;</span><span class="token punctuation">]</span><span class="token punctuation">:</span></span>
<span class="line">        seq_len <span class="token operator">=</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">)</span></span>
<span class="line">        token_positions <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>seq_len<span class="token punctuation">,</span> device<span class="token operator">=</span>x<span class="token punctuation">.</span>device<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        x <span class="token operator">=</span> x <span class="token operator">+</span> self<span class="token punctuation">.</span>attn<span class="token punctuation">(</span>self<span class="token punctuation">.</span>ln1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> token_positions<span class="token punctuation">)</span></span>
<span class="line">        x <span class="token operator">=</span> x <span class="token operator">+</span> self<span class="token punctuation">.</span>ffn<span class="token punctuation">(</span>self<span class="token punctuation">.</span>ln2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line">        <span class="token keyword">return</span> x</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="_2-3-1-root-mean-square-layer-normalization" tabindex="-1"><a class="header-anchor" href="#_2-3-1-root-mean-square-layer-normalization"><span>2.3.1 Root Mean Square Layer Normalization</span></a></h4><p>在 Transformer Block 中，每经过一个子模块首先需要 Layer Norm，这里采用 RMS Norm，具体公式如下<section><!----></section>其中<section><!----></section><!---->为可学习的参数，尺寸为 <code>(d_model,)</code>。</p><p>根据文档，代码实现时需要注意精度问题，因此代码如下：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">class</span> <span class="token class-name">RMSNorm</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span></span>
<span class="line">        self<span class="token punctuation">,</span></span>
<span class="line">        d_model<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span></span>
<span class="line">        eps<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token number">1e-5</span><span class="token punctuation">,</span></span>
<span class="line">        device<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>device <span class="token operator">|</span> <span class="token boolean">None</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span></span>
<span class="line">        dtype<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>dtype <span class="token operator">|</span> <span class="token boolean">None</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        self<span class="token punctuation">.</span>eps <span class="token operator">=</span> eps</span>
<span class="line">        self<span class="token punctuation">.</span>weight<span class="token punctuation">:</span> Float<span class="token punctuation">[</span>Tensor<span class="token punctuation">,</span> <span class="token string">&quot; d_model&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span></span>
<span class="line">            torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">,</span> dtype<span class="token operator">=</span>dtype<span class="token punctuation">)</span></span>
<span class="line">        <span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span></span>
<span class="line">        self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> Float<span class="token punctuation">[</span>Tensor<span class="token punctuation">,</span> <span class="token string">&quot; ... d_model&quot;</span><span class="token punctuation">]</span></span>
<span class="line">    <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Float<span class="token punctuation">[</span>Tensor<span class="token punctuation">,</span> <span class="token string">&quot; ... d_model&quot;</span><span class="token punctuation">]</span><span class="token punctuation">:</span></span>
<span class="line">        x_normed <span class="token operator">=</span> self<span class="token punctuation">.</span>_norm<span class="token punctuation">(</span>x<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>type_as<span class="token punctuation">(</span>x<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        <span class="token keyword">return</span> self<span class="token punctuation">.</span>weight <span class="token operator">*</span> x_normed</span>
<span class="line"></span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">_norm</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> Float<span class="token punctuation">[</span>Tensor<span class="token punctuation">,</span> <span class="token string">&quot; ...&quot;</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Float<span class="token punctuation">[</span>Tensor<span class="token punctuation">,</span> <span class="token string">&quot; ...&quot;</span><span class="token punctuation">]</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token keyword">return</span> x <span class="token operator">*</span> x<span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">.</span>add<span class="token punctuation">(</span>self<span class="token punctuation">.</span>eps<span class="token punctuation">)</span><span class="token punctuation">.</span>rsqrt<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="custom-container note"><p class="custom-container-title">Note (为什么使用 LN 而不是 BN)</p><div class="custom-container-content"><h1 id="" tabindex="-1"><a class="header-anchor" href="#"><span></span></a></h1><ol><li>在 NLP 任务中，一个 batch 内的句子长度通常是不同的。LN 是独立地对每个序列位置进行归一化的。它只针对该位置自己的特征向量计算统计量。无论序列多长，无论有多少填充，对每个 Token 的归一化操作都是独立的，完全不受影响。</li><li>BN 在训练时依赖于一个 mini-batch 的统计量，如果推理时输入的 Batch Size 与训练时不同，统计量会变得不稳定和不准确。但 LN  不依赖于 Batch Size。它的计算在训练和推理阶段是完全相同的，都是基于当前前向传播的样本自身。</li></ol></div></div><h4 id="_2-3-2-position-wise-feed-forward-network" tabindex="-1"><a class="header-anchor" href="#_2-3-2-position-wise-feed-forward-network"><span>2.3.2 Position-Wise Feed-Forward Network</span></a></h4><p>对于 FFN，常见的激活函数有<section><!----></section>后来引入 GLU (Gated Linear Units) ，即<section><!----></section>将 GLU 的门控激活函数替换为 Swish，即为 SwiGLU<section><!----></section>其中<!---->尺寸为 <code>(..., d_model)</code>，<!---->，<!---->尺寸为 <code>(d_ff, d_model)</code>，用于把<!---->从<!---->空间映射到<!---->空间，<!---->尺寸为 <code>(d_model, d_ff)</code> 用于变换回<!---->空间。一般 <!----> 或者 <!---->。</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">class</span> <span class="token class-name">SwiGlu</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span></span>
<span class="line">        self<span class="token punctuation">,</span></span>
<span class="line">        d_model<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span></span>
<span class="line">        d_ff<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span></span>
<span class="line">        device<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>device <span class="token operator">|</span> <span class="token boolean">None</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span></span>
<span class="line">        dtype<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>dtype <span class="token operator">|</span> <span class="token boolean">None</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        self<span class="token punctuation">.</span>w1 <span class="token operator">=</span> Linear<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> d_ff<span class="token punctuation">,</span> device<span class="token punctuation">,</span> dtype<span class="token punctuation">)</span></span>
<span class="line">        self<span class="token punctuation">.</span>w2 <span class="token operator">=</span> Linear<span class="token punctuation">(</span>d_ff<span class="token punctuation">,</span> d_model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> dtype<span class="token punctuation">)</span></span>
<span class="line">        self<span class="token punctuation">.</span>w3 <span class="token operator">=</span> Linear<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> d_ff<span class="token punctuation">,</span> device<span class="token punctuation">,</span> dtype<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span></span>
<span class="line">        self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> Float<span class="token punctuation">[</span>Tensor<span class="token punctuation">,</span> <span class="token string">&quot; ... d_model&quot;</span><span class="token punctuation">]</span></span>
<span class="line">    <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Float<span class="token punctuation">[</span>Tensor<span class="token punctuation">,</span> <span class="token string">&quot; ... d_model&quot;</span><span class="token punctuation">]</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token keyword">return</span> self<span class="token punctuation">.</span>w2<span class="token punctuation">(</span>silu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>w1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>w3<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="_2-3-3-causal-multi-head-self-attention" tabindex="-1"><a class="header-anchor" href="#_2-3-3-causal-multi-head-self-attention"><span>2.3.3 Causal Multi-Head Self-Attention</span></a></h4><p>多头注意力其实非常简单，本质就是维度变换而已，即</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line">Q<span class="token punctuation">,</span> K<span class="token punctuation">,</span> V <span class="token operator">=</span> <span class="token punctuation">(</span></span>
<span class="line">    rearrange<span class="token punctuation">(</span>X<span class="token punctuation">,</span> <span class="token string">&quot;... seq (h d_k) -&gt; ... h seq d_k&quot;</span><span class="token punctuation">,</span> h<span class="token operator">=</span>self<span class="token punctuation">.</span>num_heads<span class="token punctuation">)</span></span>
<span class="line">    <span class="token keyword">for</span> X <span class="token keyword">in</span> <span class="token punctuation">(</span>Q<span class="token punctuation">,</span> K<span class="token punctuation">,</span> V<span class="token punctuation">)</span></span>
<span class="line"><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>最后再把多头拼回来</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line">output <span class="token operator">=</span> rearrange<span class="token punctuation">(</span>output<span class="token punctuation">,</span> <span class="token string">&quot;... h seq_len d_k -&gt; ... seq_len (h d_k)&quot;</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>完整实现如下：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">class</span> <span class="token class-name">MultiheadSelfAttention</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span></span>
<span class="line">        self<span class="token punctuation">,</span></span>
<span class="line">        d_model<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span></span>
<span class="line">        num_heads<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span></span>
<span class="line">        theta<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">|</span> <span class="token boolean">None</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span></span>
<span class="line">        max_seq_len<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">|</span> <span class="token boolean">None</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        self<span class="token punctuation">.</span>d_model <span class="token operator">=</span> d_model</span>
<span class="line">        self<span class="token punctuation">.</span>num_heads <span class="token operator">=</span> num_heads</span>
<span class="line">        self<span class="token punctuation">.</span>d_k <span class="token operator">=</span> d_model <span class="token operator">//</span> num_heads</span>
<span class="line"></span>
<span class="line">        self<span class="token punctuation">.</span>q_proj <span class="token operator">=</span> Linear<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> d_model<span class="token punctuation">)</span></span>
<span class="line">        self<span class="token punctuation">.</span>k_proj <span class="token operator">=</span> Linear<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> d_model<span class="token punctuation">)</span></span>
<span class="line">        self<span class="token punctuation">.</span>v_proj <span class="token operator">=</span> Linear<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> d_model<span class="token punctuation">)</span></span>
<span class="line">        self<span class="token punctuation">.</span>output_proj <span class="token operator">=</span> Linear<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> d_model<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        <span class="token keyword">if</span> theta <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span> <span class="token keyword">and</span> max_seq_len <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span></span>
<span class="line">            self<span class="token punctuation">.</span>positional_embedding <span class="token operator">=</span> RotaryPositionalEmbedding<span class="token punctuation">(</span></span>
<span class="line">                theta<span class="token punctuation">,</span> self<span class="token punctuation">.</span>d_k<span class="token punctuation">,</span> max_seq_len</span>
<span class="line">            <span class="token punctuation">)</span></span>
<span class="line">        <span class="token keyword">else</span><span class="token punctuation">:</span></span>
<span class="line">            self<span class="token punctuation">.</span>positional_embedding <span class="token operator">=</span> <span class="token boolean">None</span></span>
<span class="line"></span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span></span>
<span class="line">        self<span class="token punctuation">,</span></span>
<span class="line">        x<span class="token punctuation">:</span> Float<span class="token punctuation">[</span>Tensor<span class="token punctuation">,</span> <span class="token string">&quot; ... seq_len d_model&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        token_positions<span class="token punctuation">:</span> Int<span class="token punctuation">[</span>Tensor<span class="token punctuation">,</span> <span class="token string">&quot; ... seq_len&quot;</span><span class="token punctuation">]</span> <span class="token operator">|</span> <span class="token boolean">None</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Float<span class="token punctuation">[</span>Tensor<span class="token punctuation">,</span> <span class="token string">&quot; ... seq_len d_model&quot;</span><span class="token punctuation">]</span><span class="token punctuation">:</span></span>
<span class="line">        seq_len <span class="token operator">=</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">)</span></span>
<span class="line">        mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>tril<span class="token punctuation">(</span></span>
<span class="line">            torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span></span>
<span class="line">                seq_len<span class="token punctuation">,</span></span>
<span class="line">                seq_len<span class="token punctuation">,</span></span>
<span class="line">                device<span class="token operator">=</span>x<span class="token punctuation">.</span>device<span class="token punctuation">,</span></span>
<span class="line">                dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">bool</span><span class="token punctuation">,</span></span>
<span class="line">            <span class="token punctuation">)</span></span>
<span class="line">        <span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        Q<span class="token punctuation">,</span> K<span class="token punctuation">,</span> V <span class="token operator">=</span> self<span class="token punctuation">.</span>q_proj<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>k_proj<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>v_proj<span class="token punctuation">(</span>x<span class="token punctuation">)</span></span>
<span class="line">        Q<span class="token punctuation">,</span> K<span class="token punctuation">,</span> V <span class="token operator">=</span> <span class="token punctuation">(</span></span>
<span class="line">            rearrange<span class="token punctuation">(</span>X<span class="token punctuation">,</span> <span class="token string">&quot;... seq (h d_k) -&gt; ... h seq d_k&quot;</span><span class="token punctuation">,</span> h<span class="token operator">=</span>self<span class="token punctuation">.</span>num_heads<span class="token punctuation">)</span></span>
<span class="line">            <span class="token keyword">for</span> X <span class="token keyword">in</span> <span class="token punctuation">(</span>Q<span class="token punctuation">,</span> K<span class="token punctuation">,</span> V<span class="token punctuation">)</span></span>
<span class="line">        <span class="token punctuation">)</span></span>
<span class="line">        <span class="token keyword">if</span> self<span class="token punctuation">.</span>positional_embedding<span class="token punctuation">:</span></span>
<span class="line">            Q <span class="token operator">=</span> self<span class="token punctuation">.</span>positional_embedding<span class="token punctuation">(</span>Q<span class="token punctuation">,</span> token_positions<span class="token punctuation">)</span></span>
<span class="line">            K <span class="token operator">=</span> self<span class="token punctuation">.</span>positional_embedding<span class="token punctuation">(</span>K<span class="token punctuation">,</span> token_positions<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        output <span class="token operator">=</span> scaled_dot_product_attention<span class="token punctuation">(</span>Q<span class="token punctuation">,</span> K<span class="token punctuation">,</span> V<span class="token punctuation">,</span> mask<span class="token punctuation">)</span></span>
<span class="line">        output <span class="token operator">=</span> rearrange<span class="token punctuation">(</span>output<span class="token punctuation">,</span> <span class="token string">&quot;... h seq_len d_k -&gt; ... seq_len (h d_k)&quot;</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        <span class="token keyword">return</span> self<span class="token punctuation">.</span>output_proj<span class="token punctuation">(</span>output<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="_2-3-4-scaled-dot-product-attention" tabindex="-1"><a class="header-anchor" href="#_2-3-4-scaled-dot-product-attention"><span>2.3.4 Scaled Dot-Product Attention</span></a></h4><p>注意力模块是最重要的核心，这里实现纯函数，以计算注意力<section><!----></section>其中<!---->，<!---->，<!---->。</p><p>在计算 softmax 时需要进行掩码：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line">mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>tril<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>seq_len<span class="token punctuation">,</span> seq_len<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">bool</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>最后按照公式计算即可：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">def</span> <span class="token function">scaled_dot_product_attention</span><span class="token punctuation">(</span></span>
<span class="line">    Q<span class="token punctuation">:</span> Float<span class="token punctuation">[</span>Tensor<span class="token punctuation">,</span> <span class="token string">&quot; ... queries d_k&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">    K<span class="token punctuation">:</span> Float<span class="token punctuation">[</span>Tensor<span class="token punctuation">,</span> <span class="token string">&quot; ... keys d_k&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">    V<span class="token punctuation">:</span> Float<span class="token punctuation">[</span>Tensor<span class="token punctuation">,</span> <span class="token string">&quot; ... keys d_v&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">    mask<span class="token punctuation">:</span> Bool<span class="token punctuation">[</span>Tensor<span class="token punctuation">,</span> <span class="token string">&quot; ... queries keys&quot;</span><span class="token punctuation">]</span> <span class="token operator">|</span> <span class="token boolean">None</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span></span>
<span class="line"><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Float<span class="token punctuation">[</span>Tensor<span class="token punctuation">,</span> <span class="token string">&quot; ... queries d_v&quot;</span><span class="token punctuation">]</span><span class="token punctuation">:</span></span>
<span class="line">    d_k <span class="token operator">=</span> Q<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span></span>
<span class="line">    scores <span class="token operator">=</span> Q @ K<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> math<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>d_k<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">    <span class="token keyword">if</span> mask <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span></span>
<span class="line">        scores <span class="token operator">=</span> scores<span class="token punctuation">.</span>where<span class="token punctuation">(</span>mask<span class="token punctuation">,</span> <span class="token builtin">float</span><span class="token punctuation">(</span><span class="token string">&quot;-inf&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">    attention_weights <span class="token operator">=</span> softmax<span class="token punctuation">(</span>scores<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span></span>
<span class="line">    output <span class="token operator">=</span> attention_weights @ V</span>
<span class="line"></span>
<span class="line">    <span class="token keyword">return</span> output</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="custom-container note"><p class="custom-container-title">Note (为什么自注意力需要除以 <!---->)</p><div class="custom-container-content"><h1 id="" tabindex="-1"><a class="header-anchor" href="#"><span></span></a></h1><p>假设查询向量 <!----> 和键向量 <!----> 的每个分量都是均值为 0、方差为 1 的独立随机变量，那么点积 <section><!----></section> 均值为 0，方差为 <!---->。除以 <!----> 后，点积的方差被重新缩放为 1。</p></div></div><p>最后是 softmax 实现，只需要注意减去最大值的技巧即可：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">def</span> <span class="token function">softmax</span><span class="token punctuation">(</span>x<span class="token punctuation">:</span> Float<span class="token punctuation">[</span>Tensor<span class="token punctuation">,</span> <span class="token string">&quot; ...&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Float<span class="token punctuation">[</span>Tensor<span class="token punctuation">,</span> <span class="token string">&quot; ...&quot;</span><span class="token punctuation">]</span><span class="token punctuation">:</span></span>
<span class="line">    x_max <span class="token operator">=</span> x<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>dim<span class="token operator">=</span>dim<span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">.</span>values</span>
<span class="line">    x_exp <span class="token operator">=</span> torch<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>x <span class="token operator">-</span> x_max<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">    <span class="token keyword">return</span> x_exp <span class="token operator">/</span> x_exp<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span>dim<span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="_2-3-5-relative-positional-embeddings" tabindex="-1"><a class="header-anchor" href="#_2-3-5-relative-positional-embeddings"><span>2.3.5 Relative Positional Embeddings</span></a></h4><p>RoPE 考虑将<!---->维向量分为<!---->组，每一组看作二维平面，对于每个二维平面，RoPE 应用一个旋转矩阵。即设有序列<!---->，对于<!---->，考虑分块对角矩阵<section><!----></section>每一个块矩阵为<section><!----></section>其中，<!---->，<!---->为超参数，一般取<!---->。对于向量<!---->，作变换<section><!----></section>此时<section><!----></section>注意到关键一步<section><!----></section>这表明内积仅与<!---->相对位置有关，因此完成相对位置编码。</p><p>在实际实现中，我们通过以下方式计算<section><!----></section>因此代码如下：</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">class</span> <span class="token class-name">RotaryPositionalEmbedding</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span></span>
<span class="line">        self<span class="token punctuation">,</span></span>
<span class="line">        theta<span class="token punctuation">:</span> <span class="token builtin">float</span><span class="token punctuation">,</span></span>
<span class="line">        d_k<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span></span>
<span class="line">        max_seq_len<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        self<span class="token punctuation">.</span>register_buffer<span class="token punctuation">(</span></span>
<span class="line">            <span class="token string">&quot;cis_cached&quot;</span><span class="token punctuation">,</span></span>
<span class="line">            self<span class="token punctuation">.</span>_init_cache<span class="token punctuation">(</span>theta<span class="token punctuation">,</span> d_k<span class="token punctuation">,</span> max_seq_len<span class="token punctuation">)</span><span class="token punctuation">,</span></span>
<span class="line">            persistent<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span></span>
<span class="line">        self<span class="token punctuation">,</span></span>
<span class="line">        x<span class="token punctuation">:</span> Float<span class="token punctuation">[</span>Tensor<span class="token punctuation">,</span> <span class="token string">&quot; ... seq_len d_k&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">        token_positions<span class="token punctuation">:</span> Int<span class="token punctuation">[</span>Tensor<span class="token punctuation">,</span> <span class="token string">&quot; ... seq_len&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Float<span class="token punctuation">[</span>Tensor<span class="token punctuation">,</span> <span class="token string">&quot; ... seq_len d_k&quot;</span><span class="token punctuation">]</span><span class="token punctuation">:</span></span>
<span class="line">        cos<span class="token punctuation">,</span> sin <span class="token operator">=</span> self<span class="token punctuation">.</span>cis_cached<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> token_positions<span class="token punctuation">]</span></span>
<span class="line"></span>
<span class="line">        <span class="token keyword">return</span> <span class="token punctuation">(</span>x <span class="token operator">*</span> cos<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>_rotate_half<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">*</span> sin<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">    <span class="token decorator annotation punctuation">@staticmethod</span></span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">_rotate_half</span><span class="token punctuation">(</span></span>
<span class="line">        x<span class="token punctuation">:</span> Float<span class="token punctuation">[</span>Tensor<span class="token punctuation">,</span> <span class="token string">&quot; ... d_k&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Float<span class="token punctuation">[</span>Tensor<span class="token punctuation">,</span> <span class="token string">&quot; ... d_k&quot;</span><span class="token punctuation">]</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token triple-quoted-string string">&quot;&quot;&quot;Rotate (x1, x2, x3, x4, ...) to (-x2, x1, -x4, x3, ...)&quot;&quot;&quot;</span></span>
<span class="line">        x1<span class="token punctuation">,</span> x2 <span class="token operator">=</span> x<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> x<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span></span>
<span class="line"></span>
<span class="line">        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span>x2<span class="token punctuation">,</span> x1<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape_as<span class="token punctuation">(</span>x<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">    <span class="token decorator annotation punctuation">@staticmethod</span></span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">_init_cache</span><span class="token punctuation">(</span></span>
<span class="line">        theta<span class="token punctuation">:</span> <span class="token builtin">float</span><span class="token punctuation">,</span></span>
<span class="line">        d_k<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span></span>
<span class="line">        max_seq_len<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Float<span class="token punctuation">[</span>Tensor<span class="token punctuation">,</span> <span class="token string">&quot;2 max_seq_len d_k&quot;</span><span class="token punctuation">]</span><span class="token punctuation">:</span></span>
<span class="line">        freqs <span class="token operator">=</span> theta <span class="token operator">**</span> <span class="token punctuation">(</span><span class="token operator">-</span>torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> d_k<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">/</span> d_k<span class="token punctuation">)</span></span>
<span class="line">        pos <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>max_seq_len<span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        freqs <span class="token operator">=</span> torch<span class="token punctuation">.</span>outer<span class="token punctuation">(</span>pos<span class="token punctuation">,</span> freqs<span class="token punctuation">)</span></span>
<span class="line">        freqs <span class="token operator">=</span> freqs<span class="token punctuation">.</span>repeat_interleave<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">(</span>freqs<span class="token punctuation">.</span>cos<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> freqs<span class="token punctuation">.</span>sin<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_3-training-a-transformer-lm" tabindex="-1"><a class="header-anchor" href="#_3-training-a-transformer-lm"><span>3. Training a Transformer LM</span></a></h2><h3 id="_3-1-cross-entropy-loss" tabindex="-1"><a class="header-anchor" href="#_3-1-cross-entropy-loss"><span>3.1 Cross-entropy loss</span></a></h3><h3 id="_3-2-adamw" tabindex="-1"><a class="header-anchor" href="#_3-2-adamw"><span>3.2 AdamW</span></a></h3><h3 id="_3-3-learning-rate-scheduling" tabindex="-1"><a class="header-anchor" href="#_3-3-learning-rate-scheduling"><span>3.3 Learning rate scheduling</span></a></h3><h3 id="_3-4-gradient-clipping" tabindex="-1"><a class="header-anchor" href="#_3-4-gradient-clipping"><span>3.4 Gradient clipping</span></a></h3><h2 id="_4-train-loop" tabindex="-1"><a class="header-anchor" href="#_4-train-loop"><span>4. Train Loop</span></a></h2><h3 id="_4-1-data-loader" tabindex="-1"><a class="header-anchor" href="#_4-1-data-loader"><span>4.1 Data Loader</span></a></h3><h3 id="_4-2-checkpointing" tabindex="-1"><a class="header-anchor" href="#_4-2-checkpointing"><span>4.2 Checkpointing</span></a></h3><h2 id="_5-generating-text" tabindex="-1"><a class="header-anchor" href="#_5-generating-text"><span>5. Generating text</span></a></h2></div></div><footer class="page-meta"><!----><div class="meta-item last-updated"><span class="xicon-container left meta-item-label"><!--[--><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewbox="0 0 32 32" class="xicon-icon" style="width:20px;height:20px;font-size:20px;color:;"><path d="M26 4h-4V2h-2v2h-8V2h-2v2H6c-1.1 0-2 .9-2 2v20c0 1.1.9 2 2 2h20c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zm0 22H6V12h20v14zm0-16H6V6h4v2h2V6h8v2h2V6h4v4z" fill="currentColor"></path></svg><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->Last Updated 10/16/2025, 11:40:16 AM<!--]--></span></span></div></footer><!----><div class="reco-valine-wrapper" style="display:none;"><div id="valine"></div></div></div><div class="page-catalog-container"><h5 class="tip">ON THIS PAGE</h5><ul><!--[--><!--[--><li class="page-catalog-menu-depth_2"><a aria-current="page" href="/series/stanford/cs336/01Basics.html#_1-bpe-tokenization" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="1. BPE Tokenization"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->1. BPE Tokenization<!--]--></span></span><!--[--><!--]--></a></li><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/series/stanford/cs336/01Basics.html#_1-1-bpe-tokenizer-training" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="1.1 BPE Tokenizer Training"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->1.1 BPE Tokenizer Training<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/series/stanford/cs336/01Basics.html#_1-2-bpe-tokenizer" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="1.2 BPE Tokenizer"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->1.2 BPE Tokenizer<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--]--><!--[--><li class="page-catalog-menu-depth_2"><a aria-current="page" href="/series/stanford/cs336/01Basics.html#_2-transformer-language-model-architecture" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="2. Transformer Language Model Architecture"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->2. Transformer Language Model Architecture<!--]--></span></span><!--[--><!--]--></a></li><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/series/stanford/cs336/01Basics.html#_2-1-linear-module" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="2.1 Linear Module"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->2.1 Linear Module<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/series/stanford/cs336/01Basics.html#_2-2-embedding-module" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="2.2 Embedding Module"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->2.2 Embedding Module<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/series/stanford/cs336/01Basics.html#_2-3-transformer-block" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="2.3 Transformer Block"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->2.3 Transformer Block<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--]--><!--[--><li class="page-catalog-menu-depth_2"><a aria-current="page" href="/series/stanford/cs336/01Basics.html#_3-training-a-transformer-lm" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="3. Training a Transformer LM"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->3. Training a Transformer LM<!--]--></span></span><!--[--><!--]--></a></li><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/series/stanford/cs336/01Basics.html#_3-1-cross-entropy-loss" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="3.1 Cross-entropy loss"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->3.1 Cross-entropy loss<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/series/stanford/cs336/01Basics.html#_3-2-adamw" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="3.2 AdamW"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->3.2 AdamW<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/series/stanford/cs336/01Basics.html#_3-3-learning-rate-scheduling" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="3.3 Learning rate scheduling"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->3.3 Learning rate scheduling<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/series/stanford/cs336/01Basics.html#_3-4-gradient-clipping" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="3.4 Gradient clipping"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->3.4 Gradient clipping<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--]--><!--[--><li class="page-catalog-menu-depth_2"><a aria-current="page" href="/series/stanford/cs336/01Basics.html#_4-train-loop" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="4. Train Loop"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->4. Train Loop<!--]--></span></span><!--[--><!--]--></a></li><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/series/stanford/cs336/01Basics.html#_4-1-data-loader" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="4.1 Data Loader"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->4.1 Data Loader<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--[--><li class="page-catalog-menu-depth_3"><a aria-current="page" href="/series/stanford/cs336/01Basics.html#_4-2-checkpointing" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="4.2 Checkpointing"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->4.2 Checkpointing<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--]--><!--[--><li class="page-catalog-menu-depth_2"><a aria-current="page" href="/series/stanford/cs336/01Basics.html#_5-generating-text" class="router-link-active router-link-exact-active link page-catalog-item page-catalog-item" aria-label="5. Generating text"><!--[--><!--]--><span class="xicon-container left"><!--[--><!----><!--]--><span class="xicon-content" style="color:;font-size:14px;"><!--[-->5. Generating text<!--]--></span></span><!--[--><!--]--></a></li><!--]--><!--]--></ul></div></main><!--]--></div></div><!--[--><!----><!----><!--]--><!--]--></div>
    <script type="module" src="/assets/app-aIn2dQ2S.js" defer></script>
  </body>
</html>
